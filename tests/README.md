# 爬取API测试用例

## 概述

本目录包含用于测试 `/api/cron-crawl` 爬取功能的测试脚本，确保爬虫在部署前能正常工作。

## 测试文件

- `crawl-test.mjs` - 主要测试脚本

## 使用方法

### 1. 启动开发服务器

首先确保开发服务器正在运行：

```bash
npm run dev
```

### 2. 运行测试

在另一个终端窗口中运行测试：

```bash
npm run test:crawl
```

## 测试内容

测试脚本会按顺序执行以下测试：

### 1. 服务器状态检查
- ✅ 检查开发服务器是否启动
- ✅ 验证基础API是否可访问

### 2. 爬取API测试
- ✅ 调用 `/api/cron-crawl` 端点
- ✅ 验证API响应格式
- ✅ 检查执行时间和状态码
- ✅ 验证返回的统计信息

### 3. 数据文件验证
- ✅ 检查 `src/data/crawledData.json` 是否生成
- ✅ 验证数据文件结构和格式
- ✅ 统计各平台爬取的影视数量
- ✅ 显示每个平台的示例数据

### 4. 数据读取API测试
- ✅ 测试 `/api/rankings` 端点
- ✅ 验证是否正确读取爬取数据
- ✅ 确认数据来源标识

### 5. 性能测试
- ✅ 测试API响应时间
- ✅ 验证系统性能指标

## 测试输出示例

```
🚀 开始爬取API测试...

📋 测试计划:
  1. 检查开发服务器状态
  2. 执行爬取API测试
  3. 验证生成的数据文件
  4. 测试数据读取API
  5. 性能测试
  6. 生成测试报告

⏳ 检查开发服务器状态...
✅ 开发服务器已就绪

🎯 测试爬取API...
⏱️  执行时间: 45.23秒
📡 响应状态: 200
✅ 爬取API执行成功
📊 统计信息:
   - 总影视数: 180
   - 平台数: 9
   - 更新时间: 2024-12-17 20:30:45

📁 验证数据文件...
✅ 数据文件验证通过
📊 文件统计:
   - 平台数: 9
   - 总影视数: 180
   - 文件大小: 45.67 KB
📺 各平台数据:
   - doubanMovie: 20部 (示例: 肖申克的救赎)
   - doubanTV: 20部 (示例: 我的团长我的团)
   - iqiyiMovie: 20部 (示例: 流浪地球2)
   ...

🔍 测试数据读取API...
✅ 数据读取API正常
📂 数据来源: crawled
⏰ 最后更新: 2024-12-17 20:30:45
🎉 成功读取到爬取数据!

⚡ 性能测试...
✅ 数据读取API: 35ms

📊 测试报告
==================
✅ 通过: 5/5
❌ 失败: 0/5

🎉 所有测试通过! 爬取功能正常，可以部署到Vercel

📝 保留测试数据用于查看

📝 下一步:
  - 如果测试通过，可以提交代码并部署到Vercel
  - 查看生成的 src/data/crawledData.json 确认数据格式
  - 部署后Vercel会自动设置Cron Jobs每小时运行
```

## 故障排除

### 常见问题

1. **服务器启动失败**
   - 确保端口3000没有被占用
   - 检查是否已运行 `npm run dev`

2. **爬取超时**
   - 检查网络连接
   - 某些网站可能有反爬机制

3. **数据文件不存在**
   - 确保有写入权限
   - 检查 `src/data/` 目录是否存在

### 调试技巧

- 查看控制台输出了解详细错误信息
- 检查生成的数据文件内容
- 使用浏览器直接访问API端点进行调试

## 配置选项

可以修改 `crawl-test.mjs` 中的 `TEST_CONFIG` 来调整测试参数：

```javascript
const TEST_CONFIG = {
  baseUrl: 'http://localhost:3000',  // 测试服务器地址
  timeout: 300000,                   // 超时时间（毫秒）
  dataPath: '../src/data/crawledData.json'  // 数据文件路径
};
``` 